{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Retrieve Organization Data via Cruchbase API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Gathering data on 1000 companies located accross the globe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing api in variable\n",
    "api_url = \"https://crunchbase-crunchbase-v1.p.rapidapi.com/searches/organizations\"\n",
    "\n",
    "# Setting up request body and storing in a variable\n",
    "payload = {\n",
    "    \"field_ids\": [\n",
    "        \"identifier\",\n",
    "        \"location_identifiers\",\n",
    "        \"short_description\",\n",
    "        \"rank_org\"\n",
    "    ],\n",
    "    \"limit\": 1000,\n",
    "    \"order\": [\n",
    "        {\n",
    "            \"field_id\": \"rank_org\",\n",
    "            \"sort\": \"asc\"\n",
    "        }\n",
    "    ],\n",
    "    \"query\": [\n",
    "        {\n",
    "            \"field_id\": \"location_identifiers\",\n",
    "            \"operator_id\": \"includes\",\n",
    "            \"type\": \"predicate\",\n",
    "            \"values\": [\n",
    "                \"europe\",\n",
    "                \"north-america\",\n",
    "                \"latin-america\",\n",
    "                \"asia\",\n",
    "                \"australia\",\n",
    "                \"new-zealand\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"field_id\": \"facet_ids\",\n",
    "            \"operator_id\": \"includes\",\n",
    "            \"type\": \"predicate\",\n",
    "            \"values\": [\n",
    "                \"company\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Establishing headers\n",
    "headers = {\n",
    "    \"content-type\" : \"application/json\",\n",
    "    \"x-rapidapi-key\" : \"API_KEY\",\n",
    "    \"x-rapidapi-host\" : \"HOST\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Posting request and verifying a 200 HTTP status code\n",
    "response = requests.post(api_url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding API response to JSON\n",
    "json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_response = json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding key that lists the european organizations and storing it in a variable that we can loop through\n",
    "company_list = api_response[\"entities\"]\n",
    "\n",
    "# Checking variable type to confirm it is a list\n",
    "type(company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalizing empty dictionary to append values to\n",
    "company_details = {\n",
    "    \"company_name\" : [],\n",
    "    \"company_country\" : []\n",
    "}\n",
    "\n",
    "# Looping through JSON resopnse to extract required data\n",
    "for company in company_list :\n",
    "    \n",
    "    company_name = company[\"properties\"][\"identifier\"][\"value\"]\n",
    "    company_details[\"company_name\"].append(company_name)\n",
    "    print(\"company_name:\", company_name)\n",
    "    \n",
    "    # Since there are multiple permalink dicts in the location_identifiers array, I specified the specific\n",
    "    # Array position for the permalink dict that is storing the name of the comapany's country \n",
    "    country_dict_array_position = 2\n",
    "    \n",
    "    company_country = company[\"properties\"][\"location_identifiers\"][country_dict_array_position][\"value\"]\n",
    "    company_details[\"company_country\"].append(company_country)\n",
    "    print(\"company_location:\", company_country)\n",
    "    \n",
    "    print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dictionary to make sure values were appended correctly\n",
    "company_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting dictionary into pandas dataframe and checking the first five rows\n",
    "company_df = pd.DataFrame(company_details)\n",
    "\n",
    "company_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to CSV\n",
    "company_df.to_csv('company_info_pg1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Paginating to page 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing payload to pull 1000 companies globally from page 2 utilizing after_id key\n",
    "payload = {\n",
    "    \"field_ids\": [\n",
    "        \"identifier\",\n",
    "        \"location_identifiers\",\n",
    "        \"short_description\",\n",
    "        \"rank_org\"\n",
    "    ],\n",
    "    \"limit\": 1000,\n",
    "    \"after_id\" : \"7c8beaea-b3c5-14b4-5866-dc4d4c0bc7cf\",\n",
    "    \"order\": [\n",
    "        {\n",
    "            \"field_id\": \"rank_org\",\n",
    "            \"sort\": \"asc\"\n",
    "        }\n",
    "    ],\n",
    "    \"query\": [\n",
    "        {\n",
    "            \"field_id\": \"location_identifiers\",\n",
    "            \"operator_id\": \"includes\",\n",
    "            \"type\": \"predicate\",\n",
    "            \"values\": [\n",
    "                \"europe\",\n",
    "                \"north-america\",\n",
    "                \"latin-america\",\n",
    "                \"asia\",\n",
    "                \"australia\",\n",
    "                \"new-zealand\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"field_id\": \"facet_ids\",\n",
    "            \"operator_id\": \"includes\",\n",
    "            \"type\": \"predicate\",\n",
    "            \"values\": [\n",
    "                \"company\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Posting request\n",
    "response = requests.post(api_url, data=json.dumps(payload), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for 200 Status code\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding to json and locating key that stores list of companies\n",
    "api_output = json.loads(response.text)\n",
    "\n",
    "pg2_company_list = api_output[\"entities\"]\n",
    "\n",
    "type(pg2_company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming output\n",
    "api_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through list to extract data and append to dictionary\n",
    "pg2_company_details = {\n",
    "    \"company_name\" : [],\n",
    "    \"company_country\" : []\n",
    "}\n",
    "\n",
    "for company in pg2_company_list :\n",
    "    \n",
    "    company_name = company[\"properties\"][\"identifier\"][\"value\"]\n",
    "    pg2_company_details[\"company_name\"].append(company_name)\n",
    "    print(\"company_name:\", company_name)\n",
    "    \n",
    "    country_value_array_location = 2\n",
    "    company_country = company[\"properties\"][\"location_identifiers\"][country_value_array_location][\"value\"]\n",
    "    pg2_company_details[\"company_country\"].append(company_country)\n",
    "    print(\"company_country:\", company_country)\n",
    "    \n",
    "    print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking appended values\n",
    "pg2_company_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truning into pd DF and checking first five rows\n",
    "\n",
    "pg2_companies_df = pd.DataFrame(pg2_company_details)\n",
    "\n",
    "pg2_companies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to CSV\n",
    "pg2_companies_df.to_csv('company_info_pg2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Paginating to page 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing payload to pull 1000 companies from pg 3\n",
    "\n",
    "payload = {\n",
    "    \"field_ids\": [\n",
    "        \"identifier\",\n",
    "        \"location_identifiers\",\n",
    "        \"short_description\",\n",
    "        \"rank_org\"\n",
    "    ],\n",
    "    \"limit\": 1000,\n",
    "    \"after_id\" : \"6895b3bb-e29a-05fb-1b87-ee747eeae975\",\n",
    "    \"order\": [\n",
    "        {\n",
    "            \"field_id\": \"rank_org\",\n",
    "            \"sort\": \"asc\"\n",
    "        }\n",
    "    ],\n",
    "    \"query\": [\n",
    "        {\n",
    "            \"field_id\": \"location_identifiers\",\n",
    "            \"operator_id\": \"includes\",\n",
    "            \"type\": \"predicate\",\n",
    "            \"values\": [\n",
    "                \"europe\",\n",
    "                \"north-america\",\n",
    "                \"latin-america\",\n",
    "                \"asia\",\n",
    "                \"australia\",\n",
    "                \"new-zealand\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"field_id\": \"facet_ids\",\n",
    "            \"operator_id\": \"includes\",\n",
    "            \"type\": \"predicate\",\n",
    "            \"values\": [\n",
    "                \"company\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# posting request\n",
    "api_response = requests.post(api_url, data=json.dumps(payload), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for 200 status code\n",
    "api_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding to json and locating key that stores list of apac companies\n",
    "\n",
    "api_output = json.loads(api_response.text)\n",
    "\n",
    "pg3_company_list = api_output[\"entities\"]\n",
    "\n",
    "type(pg3_company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking output\n",
    "api_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through pg3 to extract data and store in dictionary\n",
    "pg3_company_details = {\n",
    "    \"company_name\" : [],\n",
    "    \"company_country\" : []\n",
    "}\n",
    "\n",
    "for company in pg3_company_list :\n",
    "    company_name = company[\"properties\"][\"identifier\"][\"value\"]\n",
    "    pg3_company_details['company_name'].append(company_name)\n",
    "    print(company_name)\n",
    "    \n",
    "    country_value_array_location = 2\n",
    "    company_country = company[\"properties\"][\"location_identifiers\"][country_value_array_location][\"value\"]\n",
    "    pg3_company_details['company_country'].append(company_country)\n",
    "    print(company_country)\n",
    "    \n",
    "    print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dictionary\n",
    "pg3_company_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dictionary into Dataframe and checking first 5 rows\n",
    "pg3_company_df = pd.DataFrame(pg3_company_details)\n",
    "\n",
    "pg3_company_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as CSV\n",
    "pg3_company_df.to_csv(\"company_info_pg3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Paginating to page 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing payload to pull 1000 companies from pg 4\n",
    "\n",
    "payload = {\n",
    "    \"field_ids\": [\n",
    "        \"identifier\",\n",
    "        \"location_identifiers\",\n",
    "        \"short_description\",\n",
    "        \"rank_org\"\n",
    "    ],\n",
    "    \"limit\": 1000,\n",
    "    \"after_id\" : \"49f195d7-c566-4d5d-8d6b-3ac849204bd9\",\n",
    "    \"order\": [\n",
    "        {\n",
    "            \"field_id\": \"rank_org\",\n",
    "            \"sort\": \"asc\"\n",
    "        }\n",
    "    ],\n",
    "    \"query\": [\n",
    "        {\n",
    "            \"field_id\": \"location_identifiers\",\n",
    "            \"operator_id\": \"includes\",\n",
    "            \"type\": \"predicate\",\n",
    "            \"values\": [\n",
    "                \"europe\",\n",
    "                \"north-america\",\n",
    "                \"latin-america\",\n",
    "                \"asia\",\n",
    "                \"australia\",\n",
    "                \"new-zealand\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"field_id\": \"facet_ids\",\n",
    "            \"operator_id\": \"includes\",\n",
    "            \"type\": \"predicate\",\n",
    "            \"values\": [\n",
    "                \"company\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# posting request\n",
    "api_response = requests.post(api_url, data=json.dumps(payload), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking response\n",
    "api_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding to JSON, locating key that stores list of companies, and checking the type to confirm it is a list\n",
    "api_output = json.loads(api_response.text)\n",
    "\n",
    "pg4_company_list = api_output['entities']\n",
    "\n",
    "type(pg4_company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking output\n",
    "api_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through pg4 to extract data and store in dictionary\n",
    "pg4_company_details = {\n",
    "    \"company_name\" : [],\n",
    "    \"company_country\" : []\n",
    "}\n",
    "\n",
    "for company in pg4_company_list :\n",
    "    company_name = company[\"properties\"][\"identifier\"][\"value\"]\n",
    "    pg4_company_details['company_name'].append(company_name)\n",
    "    print(company_name)\n",
    "    \n",
    "    country_value_array_location = 2\n",
    "    company_country = company[\"properties\"][\"location_identifiers\"][country_value_array_location][\"value\"]\n",
    "    pg4_company_details['company_country'].append(company_country)\n",
    "    print(company_country)\n",
    "    \n",
    "    print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking appended values\n",
    "pg4_company_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dictionary into Dataframe and checking first 5 rows\n",
    "pg4_company_df = pd.DataFrame(pg4_company_details)\n",
    "\n",
    "pg4_company_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as CSV\n",
    "pg4_company_df.to_csv(\"company_info_pg4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upload Cleaned Data Into MySQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.  Upload the CountryId and RegionId fields into CountryRegions Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading CSV file containing the Country and Region Id and converting it into a pandas dataframe\n",
    "country_region_df = pd.DataFrame(pd.read_csv('country_region.csv'))\n",
    "\n",
    "country_region_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing connection to MySQL Database\n",
    "engine = create_engine('mysql+mysqldb://USERNAME:PASSWORD@HOST/DATABASE?charset=utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data to CountryRegions table\n",
    "country_region_df.to_sql('CountryRegions', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Upload Account data into Accounts Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading CSV file containing account data and converting it into a pandas dataframe\n",
    "# Companies under the AccountName column consist of companies pulled from the Crunchbase Search API above\n",
    "account_data_df = pd.DataFrame(pd.read_csv('account_data.csv'))\n",
    "\n",
    "account_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into Accounts table\n",
    "account_data_df.to_sql('Accounts', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
